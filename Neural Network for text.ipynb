{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#модель нейронной сети\n",
    "def model_for_text():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(28, 28, 1), activation='relu'))\n",
    "   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same',input_shape=(28, 28, 1), activation='relu'))\n",
    "   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(len(emnist_labels), activation=\"softmax\"))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model): #обучение сети\n",
    "    y_train= idx2numpy.convert_from_file('EMNIST/emnist_source_files/emnist-byclass-train-labels-idx1-ubyte') #обучение\n",
    "    x_train= idx2numpy.convert_from_file('EMNIST/emnist_source_files/emnist-byclass-train-images-idx3-ubyte')\n",
    "    \n",
    "    x_test= idx2numpy.convert_from_file('EMNIST/emnist_source_files/emnist-byclass-test-images-idx3-ubyte') #валидация\n",
    "    y_test= idx2numpy.convert_from_file('EMNIST/emnist_source_files/emnist-byclass-test-labels-idx1-ubyte')\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], 28, 28, 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], 28, 28, 1))\n",
    "    \n",
    "    x_train = x_train[:x_train.shape[0]//50] \n",
    "    y_train = y_train[:y_train.shape[0] //50]\n",
    "    x_test = x_test[:x_test.shape[0] //50]\n",
    "    y_test = y_test[:y_test.shape[0] //50]\n",
    "    \n",
    "    \n",
    "   \n",
    "    x_train = x_train.astype(np.float32) #norm\n",
    "    x_train /= 255.0\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    x_test /= 255.0\n",
    "    \n",
    "    \n",
    "    y_train_categorical = keras.utils.to_categorical(y_train, len(emnist_labels)) \n",
    "    y_test_categorical = keras.utils.to_categorical(y_test, len(emnist_labels))\n",
    "    \n",
    "    \n",
    "    model.fit(x_train, y_train_categorical, validation_split=0.2, validation_data=(x_test, y_test_categorical),  batch_size=64, epochs=40)\n",
    "    model.save('model_from_emnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "219/219 [==============================] - 17s 73ms/step - loss: 1.8918 - accuracy: 0.5157 - val_loss: 0.9204 - val_accuracy: 0.7231\n",
      "Epoch 2/40\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.9869 - accuracy: 0.7001 - val_loss: 0.7200 - val_accuracy: 0.7670\n",
      "Epoch 3/40\n",
      "219/219 [==============================] - 15s 70ms/step - loss: 0.7842 - accuracy: 0.7444 - val_loss: 0.6462 - val_accuracy: 0.7889\n",
      "Epoch 4/40\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.6868 - accuracy: 0.7684 - val_loss: 0.5904 - val_accuracy: 0.8044\n",
      "Epoch 5/40\n",
      "219/219 [==============================] - 14s 66ms/step - loss: 0.6204 - accuracy: 0.7870 - val_loss: 0.5652 - val_accuracy: 0.8087\n",
      "Epoch 6/40\n",
      "219/219 [==============================] - 14s 66ms/step - loss: 0.5708 - accuracy: 0.8002 - val_loss: 0.5544 - val_accuracy: 0.8100\n",
      "Epoch 7/40\n",
      "219/219 [==============================] - 16s 72ms/step - loss: 0.5381 - accuracy: 0.8099 - val_loss: 0.5666 - val_accuracy: 0.8100\n",
      "Epoch 8/40\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.5105 - accuracy: 0.8155 - val_loss: 0.5736 - val_accuracy: 0.8044\n",
      "Epoch 9/40\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.4773 - accuracy: 0.8281 - val_loss: 0.5496 - val_accuracy: 0.8147\n",
      "Epoch 10/40\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.4577 - accuracy: 0.8341 - val_loss: 0.5553 - val_accuracy: 0.8151\n",
      "Epoch 11/40\n",
      "219/219 [==============================] - 16s 75ms/step - loss: 0.4321 - accuracy: 0.8372 - val_loss: 0.5506 - val_accuracy: 0.8121\n",
      "Epoch 12/40\n",
      "219/219 [==============================] - 17s 77ms/step - loss: 0.4196 - accuracy: 0.8444 - val_loss: 0.5599 - val_accuracy: 0.8220\n",
      "Epoch 13/40\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.3972 - accuracy: 0.8475 - val_loss: 0.5501 - val_accuracy: 0.8207\n",
      "Epoch 14/40\n",
      "219/219 [==============================] - 16s 75ms/step - loss: 0.3867 - accuracy: 0.8544 - val_loss: 0.5504 - val_accuracy: 0.8224\n",
      "Epoch 15/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.3741 - accuracy: 0.8562 - val_loss: 0.5540 - val_accuracy: 0.8224\n",
      "Epoch 16/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.3646 - accuracy: 0.8586 - val_loss: 0.5807 - val_accuracy: 0.8143\n",
      "Epoch 17/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.3493 - accuracy: 0.8650 - val_loss: 0.5653 - val_accuracy: 0.8250\n",
      "Epoch 18/40\n",
      "219/219 [==============================] - 15s 66ms/step - loss: 0.3361 - accuracy: 0.8701 - val_loss: 0.5583 - val_accuracy: 0.8177\n",
      "Epoch 19/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.3248 - accuracy: 0.8717 - val_loss: 0.5811 - val_accuracy: 0.8156\n",
      "Epoch 20/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.3180 - accuracy: 0.8778 - val_loss: 0.5829 - val_accuracy: 0.8216\n",
      "Epoch 21/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.3149 - accuracy: 0.8766 - val_loss: 0.5717 - val_accuracy: 0.8233\n",
      "Epoch 22/40\n",
      "219/219 [==============================] - 15s 66ms/step - loss: 0.2990 - accuracy: 0.8833 - val_loss: 0.5953 - val_accuracy: 0.8164\n",
      "Epoch 23/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2934 - accuracy: 0.8862 - val_loss: 0.6121 - val_accuracy: 0.8194\n",
      "Epoch 24/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2824 - accuracy: 0.8897 - val_loss: 0.5818 - val_accuracy: 0.8207\n",
      "Epoch 25/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2767 - accuracy: 0.8922 - val_loss: 0.5860 - val_accuracy: 0.8199\n",
      "Epoch 26/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2696 - accuracy: 0.8920 - val_loss: 0.6508 - val_accuracy: 0.8126\n",
      "Epoch 27/40\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.2630 - accuracy: 0.8947 - val_loss: 0.6328 - val_accuracy: 0.8177\n",
      "Epoch 28/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2669 - accuracy: 0.8948 - val_loss: 0.6233 - val_accuracy: 0.8220\n",
      "Epoch 29/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2594 - accuracy: 0.8960 - val_loss: 0.6223 - val_accuracy: 0.8199\n",
      "Epoch 30/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2540 - accuracy: 0.8988 - val_loss: 0.6115 - val_accuracy: 0.8203\n",
      "Epoch 31/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2366 - accuracy: 0.9056 - val_loss: 0.6570 - val_accuracy: 0.8190\n",
      "Epoch 32/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2450 - accuracy: 0.9029 - val_loss: 0.6584 - val_accuracy: 0.8190\n",
      "Epoch 33/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2414 - accuracy: 0.9041 - val_loss: 0.6592 - val_accuracy: 0.8156\n",
      "Epoch 34/40\n",
      "219/219 [==============================] - 15s 66ms/step - loss: 0.2263 - accuracy: 0.9106 - val_loss: 0.6697 - val_accuracy: 0.8134\n",
      "Epoch 35/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2243 - accuracy: 0.9104 - val_loss: 0.6810 - val_accuracy: 0.8164\n",
      "Epoch 36/40\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.2250 - accuracy: 0.9100 - val_loss: 0.6892 - val_accuracy: 0.8212\n",
      "Epoch 37/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2296 - accuracy: 0.9109 - val_loss: 0.6834 - val_accuracy: 0.8272\n",
      "Epoch 38/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2074 - accuracy: 0.9168 - val_loss: 0.7003 - val_accuracy: 0.8199\n",
      "Epoch 39/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2169 - accuracy: 0.9138 - val_loss: 0.7229 - val_accuracy: 0.8147\n",
      "Epoch 40/40\n",
      "219/219 [==============================] - 15s 67ms/step - loss: 0.2133 - accuracy: 0.9145 - val_loss: 0.6960 - val_accuracy: 0.8169\n"
     ]
    }
   ],
   "source": [
    "model=model_for_text()\n",
    "model_train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#подготовка изображения и получение контуров с подготовленноко изображения\n",
    "def image_preparation(path):\n",
    "  img = cv2.imread(path)\n",
    "\n",
    "  gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#серый тон\n",
    "\n",
    "  ret, tresh=cv2.threshold(gray,0,255,cv2.THRESH_BINARY)# черно-белый\n",
    "\n",
    "  img_erode=cv2.erode(tresh, np.ones((3,3),np.uint8),iterations=1)#улучшение четкости\n",
    "\n",
    "  contours, hierarchy=cv2.findContours(img_erode, cv2.RETR_TREE ,cv2.CHAIN_APPROX_SIMPLE)#получение контуров\n",
    "  \n",
    "  output = img.copy()\n",
    "  letters = []\n",
    "  for idx, contour  in enumerate(contours):\n",
    "    (x, y, w, h) = cv2.boundingRect(contour)\n",
    "    if hierarchy[0][idx][3] == 0:\n",
    "      cv2.rectangle(output, (x, y), (x + w, y + h), (70, 0, 0), 1)\n",
    "      \n",
    "      letter_crop = gray[y:y + h, x:x + w]\n",
    "      size_max = max(w, h)\n",
    "      letter_square = 255 * np.ones(shape=[size_max, size_max], dtype=np.uint8)\n",
    "      if w > h:\n",
    "        \n",
    "        y_pos = size_max//2 - h//2\n",
    "        letter_square[y_pos:y_pos + h, 0:w] = letter_crop\n",
    "      elif w < h:\n",
    "        \n",
    "        x_pos = size_max//2 - w//2\n",
    "        letter_square[0:h, x_pos:x_pos + w] = letter_crop\n",
    "      else:\n",
    "        \n",
    "        letter_square = letter_crop\n",
    "      letters.append((x, w, cv2.resize(letter_square, (28,28), interpolation=cv2.INTER_AREA)))\n",
    "    \n",
    "    \n",
    "  letters.sort(key=lambda x: x[0], reverse=False)\n",
    "  #cv2.imshow(\"Output\", output)\n",
    "  #cv2.waitKey(0)\n",
    "  return letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(model, letters): #поворот ихображения\n",
    "    img_arr = np.expand_dims(letters, axis=0)\n",
    "    img_arr = 1 - img_arr/255.0\n",
    "    img_arr[0] = np.rot90(img_arr[0], 3)\n",
    "    img_arr[0] = np.fliplr(img_arr[0])\n",
    "    img_arr = img_arr.reshape((1, 28, 28, 1))\n",
    "\n",
    "    predict = model.predict([img_arr])\n",
    "    result = np.argmax(predict, axis=1)\n",
    "    return chr(emnist_labels[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_txt(model, img): #вывод текста\n",
    "    letters = image_preparation(img)\n",
    "    text = \"\"\n",
    "    for i in range(len(letters)):\n",
    "        dn = letters[i+1][0] - letters[i][0] - letters[i][1] if i < len(letters) - 1 else 0\n",
    "        text += predict_img(model, letters[i][2])\n",
    "        if (dn > letters[i][1]/4):\n",
    "            text += ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hMdTW\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('model_from_emnist.h5')\n",
    "text = img_to_txt(model, \"text_6.png\")\n",
    "#text = img_to_txt(model, \"text_2.png\")\n",
    "#text = img_to_txt(model, \"text_3.png\")\n",
    "#text = img_to_txt(model, \"text_4.png\")\n",
    "#text = img_to_txt(model, \"text_5.png\")\n",
    "#text = img_to_txt(model, \"text_6.png\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
